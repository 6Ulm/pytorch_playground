{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from os.path import join, expanduser, exists\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.text import TextDataset\n",
    "from core.loop import Loop, Stepper\n",
    "from core.iterators import SequenceIterator\n",
    "from core.schedule import CosineAnnealingLR\n",
    "from core.callbacks import EarlyStopping, Checkpoint, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, download_path, expected_size):\n",
    "    if exists(download_path):\n",
    "        print('The file was already downloaded')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        r = urlopen(url)\n",
    "    except URLError as e:\n",
    "        print(f'Cannot download the data. Error: {e}')\n",
    "        return\n",
    "    \n",
    "    if r.status != 200:\n",
    "        print(f'HTTP Error: {r.status}')\n",
    "        return\n",
    "    \n",
    "    data = r.read()\n",
    "    if len(data) != expected_size:\n",
    "        print(f'Invalid downloaded array size: {len(data)}')\n",
    "        return\n",
    "    \n",
    "    text = data.decode(encoding='utf-8')\n",
    "    with open(download_path, 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "    print(f'Downloaded: {download_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(URL, PATH, 600901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = expanduser(join('~', 'data', 'fastai', 'nietzsche'))\n",
    "TRAIN_DIR = join(ROOT, 'trn')\n",
    "VALID_DIR = join(ROOT, 'val')\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_factors, batch_size, n_hidden,\n",
    "                 n_recurrent=1, architecture=nn.RNN, device=DEVICE):\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_recurrent = n_recurrent\n",
    "        self.device = device\n",
    "\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, n_factors)\n",
    "        self.rnn = architecture(n_factors, n_hidden, num_layers=n_recurrent)\n",
    "        self.out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.hidden_state = self.init_hidden(batch_size).to(device)\n",
    "        self.batch_size = batch_size\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        bs = batch.size(1)\n",
    "        if bs != self.batch_size:\n",
    "            self.hidden_state = self.init_hidden(bs)\n",
    "            self.batch_size = bs\n",
    "        embeddings = self.embed(batch)\n",
    "        rnn_outputs, h = self.rnn(embeddings, self.hidden_state)\n",
    "        self.hidden_state = truncate_history(h)\n",
    "        linear = self.out(rnn_outputs)\n",
    "        return F.log_softmax(linear, dim=-1).view(-1, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if type(self.rnn) == nn.LSTM:\n",
    "            # an LSTM cell requires two hidden states\n",
    "            h = torch.zeros(2, self.n_recurrent, batch_size, self.n_hidden)\n",
    "        else:\n",
    "            h = torch.zeros(self.n_recurrent, batch_size, self.n_hidden)\n",
    "        return h.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_history(v):\n",
    "    if type(v) == torch.Tensor:\n",
    "        return v.detach()\n",
    "    else:\n",
    "        return tuple(truncate_history(x) for x in v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, field, seed, n=500):\n",
    "    string = seed\n",
    "    for i in range(n):\n",
    "        indexes = field.numericalize(string)\n",
    "        predictions = model(indexes.transpose(0, 1))\n",
    "        last_output = predictions[-1]\n",
    "        [most_probable] = torch.multinomial(last_output.exp(), 1)\n",
    "        char = field.vocab.itos[most_probable]\n",
    "        seed = seed[1:] + char\n",
    "        string += char\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(text, width=80):\n",
    "    print('\\n'.join(textwrap.wrap(text, width=width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text(model, field, seed):\n",
    "    pretty_print(generate_text(model, field, seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(bptt, batch_size, min_freq):\n",
    "    field = Field(lower=True, tokenize=list)\n",
    "    dataset = TextDataset(field, min_freq)\n",
    "    factory = lambda seq: SequenceIterator(seq, bptt, batch_size)\n",
    "    dataset.build(train=TRAIN_DIR, valid=VALID_DIR, iterator_factory=factory)\n",
    "    return dataset, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "bptt = 8\n",
    "min_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, field = create_dataset(bptt, batch_size, min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, field, arch=nn.LSTM, n_epochs=100, \n",
    "          n_factors=50, n_hidden=256, n_recurrent=1,\n",
    "          callbacks=None):\n",
    "    \n",
    "    model = RNN(\n",
    "        dataset.vocab_size,\n",
    "        n_factors,\n",
    "        batch_size,\n",
    "        n_hidden,\n",
    "        n_recurrent,\n",
    "        architecture=arch)\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "    cycle_length = dataset['train'].total_iters\n",
    "    scheduler = CosineAnnealingLR(optimizer, t_max=cycle_length)\n",
    "    stepper = Stepper(model, optimizer, scheduler, F.nll_loss)\n",
    "\n",
    "    loop = Loop(stepper)\n",
    "    loop.run(train_data=dataset['train'],\n",
    "             valid_data=dataset['valid'],\n",
    "             callbacks=callbacks,\n",
    "             epochs=n_epochs)\n",
    "    \n",
    "    model.load_state_dict(torch.load(checkpoint.best_model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: train - 1.6699 valid - 1.6919\n",
      "Epoch    2: train - 1.5128 valid - 1.5669\n",
      "Epoch    3: train - 1.4296 valid - 1.4882\n",
      "Epoch    4: train - 1.3588 valid - 1.4431\n",
      "Epoch    5: train - 1.3095 valid - 1.4151\n",
      "Epoch    6: train - 1.2804 valid - 1.3920\n",
      "Epoch    7: train - 1.2800 valid - 1.4024\n",
      "Epoch    8: train - 1.2463 valid - 1.3784\n",
      "Epoch    9: train - 1.2186 valid - 1.3833\n",
      "Epoch   10: train - 1.1936 valid - 1.3592\n",
      "Epoch   11: train - 1.1684 valid - 1.3507\n",
      "Epoch   12: train - 1.1480 valid - 1.3528\n",
      "Epoch   13: train - 1.1339 valid - 1.3554\n"
     ]
    }
   ],
   "source": [
    "model = train(dataset, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For those new had to at the whoth, selhomity), be, of sumpareriations and\n",
      "according to be suspition from a proved to immediately and found, of inness in\n",
      "the free spirit, folly, a magner; it is defers in any christians, also, has\n",
      "solit; he finds nowadays in its possible for it who is thus necessarily\n",
      "subjects, indiffained, which to senwerful not the \"falsisest she herd of\n",
      "indispensed.--loationing and by no god construction of a dimestion of expedients\n",
      "and father, indestructive, knowledge up to beethovers\n"
     ]
    }
   ],
   "source": [
    "show_text(model, field, 'For thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in (nn.RNN, nn.GRU, nn.LSTM):\n",
    "    model = train(dataset, field, arch)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=3), Logger(), checkpoint]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
