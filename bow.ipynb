{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f00364f1d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(examples):\n",
    "    return [(s.split(), l) for s, l in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split([\n",
    "    ('me gusta comer en la cafeteria', 'SPANISH'),\n",
    "    ('Give it to me', 'ENGLISH'),\n",
    "    ('No creo que sea una buena idea', 'SPANISH'),\n",
    "    ('No it is not a good idea to get lost at sea', 'ENGLISH')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = split([\n",
    "    ('Yo creo que si', 'SPANISH'),\n",
    "    ('it is lost on me', 'ENGLISH')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "for sentence, _ in data + test_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {'SPANISH': 0, 'ENGLISH': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_index)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_index):\n",
    "    vec = torch.zeros(len(word_to_index))\n",
    "    for word in sentence:\n",
    "        vec[word_to_index[word]] += 1\n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_index):\n",
    "    return torch.LongTensor([label_to_index[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = make_bow_vector('not a good sea'.split(), word_to_index)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset):\n",
    "    with torch.no_grad():\n",
    "        for instance, label in dataset:\n",
    "            bow_vec = make_bow_vector(instance, word_to_index)\n",
    "            log_probs = model(bow_vec)\n",
    "            print(instance, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo', 'creo', 'que', 'si'] tensor([[-0.6250, -0.7662]])\n",
      "['it', 'is', 'lost', 'on', 'me'] tensor([[-0.5870, -0.8119]])\n"
     ]
    }
   ],
   "source": [
    "test(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020 - loss: 0.1962\n",
      "Epoch: 040 - loss: 0.0954\n",
      "Epoch: 060 - loss: 0.0629\n",
      "Epoch: 080 - loss: 0.0469\n",
      "Epoch: 100 - loss: 0.0374\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for instance, label in data:\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_bow_vector(instance, word_to_index)\n",
    "        target = make_target(label, label_to_index)\n",
    "        log_probs = model(bow_vec)\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if epoch % 20 == 19:\n",
    "        print('Epoch: %03d - loss: %2.4f' % (epoch + 1, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo', 'creo', 'que', 'si'] tensor([[-0.1210, -2.1721]])\n",
      "['it', 'is', 'lost', 'on', 'me'] tensor([[-2.7767, -0.0643]])\n"
     ]
    }
   ],
   "source": [
    "test(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings: Encoding Lexical Semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f00364f1d70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [\n",
    "    ([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "     for i in range(len(test_sentence) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_index = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        hid = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(hid)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 loss: 523.4871\n",
      "Epoch 002 loss: 521.0430\n",
      "Epoch 003 loss: 518.6119\n",
      "Epoch 004 loss: 516.1947\n",
      "Epoch 005 loss: 513.7917\n",
      "Epoch 006 loss: 511.4015\n",
      "Epoch 007 loss: 509.0222\n",
      "Epoch 008 loss: 506.6536\n",
      "Epoch 009 loss: 504.2950\n",
      "Epoch 010 loss: 501.9466\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([\n",
    "            word_to_index[w] for w in context], \n",
    "            dtype=torch.long)\n",
    "        \n",
    "        target = torch.tensor(\n",
    "            [word_to_index[target]], \n",
    "            dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('Epoch %03d loss: %2.4f' % (epoch + 1, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Continuous Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, context_size=CONTEXT_SIZE):\n",
    "    cs = context_size\n",
    "    for i in range(cs, len(text) - cs):\n",
    "        left = [text[i - c] for c in range(cs, 0, -1)]\n",
    "        right = [text[i + c] for c in range(1, cs + 1)]\n",
    "        context = left + right\n",
    "        target = text[i]\n",
    "        row = [word_to_index[word] for word in context + [target]]\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsIterator:\n",
    "    \n",
    "    def __init__(self, dataset, bs=8, shuffle=True):\n",
    "        self.dataset = np.asarray(list(dataset))\n",
    "        self.bs = bs\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = math.ceil(len(self.dataset) / self.bs)\n",
    "        self.current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            index = np.random.permutation(self.dataset.shape[0])\n",
    "            self.dataset = self.dataset[index]\n",
    "        self.current = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        i, bs = self.current, self.bs\n",
    "        batch = np.asarray(self.dataset[i*bs:(i + 1)*bs])\n",
    "        context, target = [\n",
    "            torch.tensor(x, dtype=torch.long) \n",
    "            for x in (batch[:, :-1], batch[:, -1])]\n",
    "        self.current += 1\n",
    "        return context, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(words, dtype=torch.long):\n",
    "    return torch.tensor([word_to_index[word] for row in word for word in words], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, vocab_size)\n",
    "    \n",
    "    def forward(self, context):\n",
    "        embed = self.embedding(context)\n",
    "        embed_sum = torch.sum(embed, dim=1)\n",
    "        hid = F.relu(self.fc1(embed_sum))\n",
    "        out = self.fc2(hid)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 loss: 2.905662\n",
      "Epoch 020 loss: 0.037405\n",
      "Epoch 030 loss: 0.005807\n",
      "Epoch 040 loss: 0.002410\n",
      "Epoch 050 loss: 0.000684\n",
      "Epoch 060 loss: 0.000537\n",
      "Epoch 070 loss: 0.000229\n",
      "Epoch 080 loss: 0.000280\n",
      "Epoch 090 loss: 0.000168\n",
      "Epoch 100 loss: 0.000015\n"
     ]
    }
   ],
   "source": [
    "bs = 8\n",
    "n_epochs = 100\n",
    "dataset_iterator = WordsIterator(create_dataset(raw_text))\n",
    "\n",
    "model = CBOW(vocab_size, 150)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.999, nesterov=True, lr=0.001)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for context, target in dataset_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(context)\n",
    "        loss = F.nll_loss(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if epoch % 10 == 9:\n",
    "        print('Epoch %03d loss: %2.6f' % (epoch + 1, epoch_loss))\n",
    "    losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efff478cda0>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efff46c8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolution process of a pattern\n"
     ]
    }
   ],
   "source": [
    "context = 'evolution process a pattern'.split()\n",
    "indexes = [word_to_index[w] for w in context]\n",
    "log_preds = model(torch.LongTensor([indexes]))\n",
    "target = index_to_word[log_preds.argmax().item()]\n",
    "prediction = context[:CONTEXT_SIZE] + [target] + context[CONTEXT_SIZE:]\n",
    "print(' '.join(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
