{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with RNN\n",
    "\n",
    "In this notebook, we're going to classify lyrics authors. As a bonus, we'll build our own lyrics generator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Downloading\n",
    "\n",
    "The lyrics data we're going to use in this analysis is taken from [azlyrics.com](https://www.azlyrics.com) platform. We use a simple [HTML parser](../azlyrics.py) to collect a small subset of all available texts. \n",
    "\n",
    "> **Disclaimer:** The license agreement of the azlyrics platform allows to use their data for educational and personal purposes only. All lyrics texts used in this notebook is a property of their owners.\n",
    "\n",
    "Each song is saved into a separate text file, and the files are gathered into repository with author's name. Also, each author's folder contains a CSV file that maps the song file name (represented as an ordered number) onto original song name.\n",
    "\n",
    "The folders structure used in this analysis looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACDC\r\n",
      "Black Sabbath\r\n",
      "Creedence Clearwater Revival\r\n",
      "Deep Purple\r\n",
      "Dio\r\n",
      "Grateful Dead\r\n",
      "King Crimson\r\n",
      "Nazareth\r\n",
      "Rainbow\r\n",
      "Who\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 ~/data/azlyrics/many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single folder contains bunch of enumerated `*.txt` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.txt\t17.txt\t24.txt\t31.txt\t39.txt\t46.txt\t53.txt\t60.txt\t68.txt\r\n",
      "10.txt\t18.txt\t25.txt\t32.txt\t3.txt\t47.txt\t54.txt\t61.txt\t69.txt\r\n",
      "11.txt\t19.txt\t26.txt\t33.txt\t40.txt\t48.txt\t55.txt\t62.txt\t6.txt\r\n",
      "12.txt\t1.txt\t27.txt\t34.txt\t41.txt\t49.txt\t56.txt\t63.txt\t7.txt\r\n",
      "13.txt\t20.txt\t28.txt\t35.txt\t42.txt\t4.txt\t57.txt\t64.txt\t8.txt\r\n",
      "14.txt\t21.txt\t29.txt\t36.txt\t43.txt\t50.txt\t58.txt\t65.txt\t9.txt\r\n",
      "15.txt\t22.txt\t2.txt\t37.txt\t44.txt\t51.txt\t59.txt\t66.txt\tsongs.csv\r\n",
      "16.txt\t23.txt\t30.txt\t38.txt\t45.txt\t52.txt\t5.txt\t67.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ~/data/azlyrics/many/Rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.home() / 'data' / 'azlyrics' / 'many'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs(author):\n",
    "    \"\"\"Gets list of songs for a specifc author\"\"\"\n",
    "    \n",
    "    records = []\n",
    "    with open(PATH.joinpath(author, 'songs.csv')) as file:\n",
    "        for line in file:\n",
    "            order, _, header = line.strip().partition(',')\n",
    "            order = int(order)\n",
    "            record = {'index': order, 'song': header}\n",
    "            with open(PATH.joinpath(author, f'{order}.txt')) as lyrics:\n",
    "                record['text'] = lyrics.read()\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dio_songs = get_songs('Dio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stand Up And Shout</td>\n",
       "      <td>It's the same old song\\nyou gotta be somewhere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holy Diver</td>\n",
       "      <td>Holy Diver\\nYou've been down too long in the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gypsy</td>\n",
       "      <td>Yeah gypsy\\nshe was straight from home\\nbut yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caught In The Middle</td>\n",
       "      <td>Looking inside of yourself\\nyou might see some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Talk To Strangers</td>\n",
       "      <td>Don't talk to strangers hmm hmm hmm hmm hmm hm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          song  \\\n",
       "index                            \n",
       "0           Stand Up And Shout   \n",
       "1                   Holy Diver   \n",
       "2                        Gypsy   \n",
       "3         Caught In The Middle   \n",
       "4      Don't Talk To Strangers   \n",
       "\n",
       "                                                    text  \n",
       "index                                                     \n",
       "0      It's the same old song\\nyou gotta be somewhere...  \n",
       "1      Holy Diver\\nYou've been down too long in the m...  \n",
       "2      Yeah gypsy\\nshe was straight from home\\nbut yo...  \n",
       "3      Looking inside of yourself\\nyou might see some...  \n",
       "4      Don't talk to strangers hmm hmm hmm hmm hmm hm...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dio_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the same old song\n",
      "you gotta be somewhere at sometime\n",
      "and they'll never let you fly\n",
      "It's like broken glass\n",
      "you get cut before you see it\n",
      "so open up your eyes\n",
      "\n",
      "You've got desire\n",
      "so let it out\n",
      "you've got the power\n",
      "stand up and shout\n",
      "shout, shout, stand up and shout\n",
      "\n",
      "You got wings of steel\n",
      "but they never really move you\n",
      "you only seem to crawl\n",
      "You've been nailed to the wheel\n",
      "but never really turning\n",
      "you know you've got to work it out\n",
      "\n",
      "You've got desire\n",
      "so let it out\n",
      "you've got the power\n",
      "stand up and shout\n",
      "shout, shout, stand up and shout\n",
      "\n",
      "Let it out\n",
      "\n",
      "You are the strongest chain\n",
      "and you're not just some reflection\n",
      "so never hide again\n",
      "You are the driver\n",
      "you own the road\n",
      "you are the fire -- go on, explode\n",
      "\n",
      "Let it out\n",
      "\n",
      "Stand up and shout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dio_songs.loc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, expanduser, exists\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchtext import vocab, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = expanduser(join('~', 'data', 'fastai', 'nietzsche', 'nietzsche.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, download_path, expected_size):\n",
    "    if exists(download_path):\n",
    "        print('The file was already downloaded')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        r = urlopen(url)\n",
    "    except URLError as e:\n",
    "        print(f'Cannot download the data. Error: {e}')\n",
    "        return\n",
    "    \n",
    "    if r.status != 200:\n",
    "        print(f'HTTP Error: {r.status}')\n",
    "        return\n",
    "    \n",
    "    data = r.read()\n",
    "    if len(data) != expected_size:\n",
    "        print(f'Invalid downloaded array size: {len(data)}')\n",
    "        return\n",
    "    \n",
    "    text = data.decode(encoding='utf-8')\n",
    "    with open(download_path, 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "    print(f'Downloaded: {download_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was already downloaded\n"
     ]
    }
   ],
   "source": [
    "download(URL, PATH, 600901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(path, train_size=0.8):\n",
    "    with open(path) as file:\n",
    "        content = file.read()\n",
    "    n = int(len(content) * train_size)\n",
    "    return content[:n], content[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480714\n",
      "120179\n"
     ]
    }
   ],
   "source": [
    "train_text, valid_text = split(PATH)\n",
    "print(len(train_text))\n",
    "print(len(valid_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 85\n"
     ]
    }
   ],
   "source": [
    "text = train_text + valid_text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print(f'Vocab size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {c: i for i, c in enumerate(chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(chars)}\n",
    "train_indicies = [char_to_index[char] for char in train_text]\n",
    "valid_indicies = [char_to_index[char] for char in valid_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
